{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shane/projects/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from accelerate import Accelerator\n",
    "from diffusers import DiffusionPipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_mem = True\n",
    "#MODEL_NAME = \"stabilityai/stable-diffusion-2-1\"\n",
    "MODEL_NAME = \"CompVis/stable-diffusion-v1-4\"\n",
    "INSTANCE_DIR = \"./content/data/sks\"\n",
    "CLASS_NAME = \"dog\"\n",
    "CLASS_DIR = f\"./content/data/{CLASS_NAME}\"\n",
    "TOKEN_NAME = \"sks\"\n",
    "OUTPUT_DIR = \"./content/stable_diffusion_weights/sks\"\n",
    "PRIOR_LOSS_WEIGHT = 1.0\n",
    "RESOLUTION = 512\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "GRAD_ACCUMULATION_STEPS = 1\n",
    "LEARNING_RATE = 5e-6\n",
    "LR_SCHEDULER = \"constant\"\n",
    "LR_WARMUP_STEPS = 0\n",
    "NUM_CLASS_IMAGES = 200\n",
    "MAX_TRAIN_STEPS = 800\n",
    "SAMPLE_BATCH_SIZE = 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep host"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce RTX 2070 SUPER, 8192 MiB, 7674 MiB\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/train_dreambooth.py\n",
    "#!wget -q https://raw.githubusercontent.com/huggingface/diffusers/main/examples/text_to_image/train_text_to_image.py\n",
    "#!pip install git+https://github.com/huggingface/diffusers\n",
    "#!pip install -U -r https://raw.githubusercontent.com/huggingface/diffusers/main/examples/dreambooth/requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!mkdir -p $INSTANCE_DIR\n",
    "!mkdir -p $OUTPUT_DIR"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\n",
    "    \"--pretrained_model_name_or_path=\"+MODEL_NAME,\n",
    "    \"--instance_data_dir=\"+INSTANCE_DIR,\n",
    "    \"--class_data_dir=\"+CLASS_DIR,\n",
    "    \"--output_dir=\"+OUTPUT_DIR,\n",
    "    \"--with_prior_preservation\",\n",
    "    \"--prior_loss_weight=\"+str(PRIOR_LOSS_WEIGHT),\n",
    "    \"--instance_prompt='photo of \"+TOKEN_NAME + \" \" + CLASS_NAME + \"'\",\n",
    "    \"--class_prompt='photo of \" + CLASS_NAME + \"'\",\n",
    "    \"--resolution=\"+str(RESOLUTION),\n",
    "    \"--train_batch_size=\"+str(TRAIN_BATCH_SIZE),\n",
    "    \"--gradient_accumulation_steps=\"+str(GRAD_ACCUMULATION_STEPS),\n",
    "    \"--learning_rate=\"+str(LEARNING_RATE),\n",
    "    \"--lr_scheduler=\"+str(LR_SCHEDULER),\n",
    "    \"--lr_warmup_steps=\"+str(LR_WARMUP_STEPS),\n",
    "    \"--num_class_images=\"+str(NUM_CLASS_IMAGES),\n",
    "    \"--max_train_steps=\"+str(MAX_TRAIN_STEPS),\n",
    "]\n",
    "if low_mem:\n",
    "    args += [\n",
    "        \"--sample_batch_size=\"+str(SAMPLE_BATCH_SIZE),\n",
    "        \"--mixed_precision='fp16'\",\n",
    "        \"--enable_xformers_memory_efficient_attention\",\n",
    "        \"--set_grads_to_none\",\n",
    "        \"--use_8bit_adam\"\n",
    "    ]\n",
    "elif not low_mem:\n",
    "    args += [\n",
    "        \"--train_text_encoder\"\n",
    "    ]\n",
    "train_args = \" \".join(f'{w}' for w in args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/accelerator.py:249: FutureWarning: `logging_dir` is deprecated and will be removed in version 0.18.0 of 🤗 Accelerate. Use `project_dir` instead.\n",
      "  warnings.warn(\n",
      "04/01/2023 12:58:40 - INFO - __main__ - Distributed environment: DEEPSPEED\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda:0\n",
      "\n",
      "Mixed precision type: fp16\n",
      "ds_config: {'train_batch_size': 'auto', 'train_micro_batch_size_per_gpu': 'auto', 'gradient_accumulation_steps': 1, 'zero_optimization': {'stage': 2, 'offload_optimizer': {'device': 'cpu'}, 'offload_param': {'device': 'cpu'}, 'stage3_gather_16bit_weights_on_model_save': False}, 'steps_per_print': inf, 'fp16': {'enabled': True, 'auto_cast': True}, 'bf16': {'enabled': False}}\n",
      "\n",
      "You are using a model of type clip_text_model to instantiate a model of type . This is not supported for all configurations of models and can yield errors.\n",
      "{'clip_sample_range', 'thresholding', 'variance_type', 'dynamic_thresholding_ratio', 'prediction_type', 'sample_max_value'} was not found in config. Values will be initialized to default values.\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:402: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "{'norm_num_groups'} was not found in config. Values will be initialized to default values.\n",
      "{'conv_out_kernel', 'use_linear_projection', 'timestep_post_act', 'time_embedding_type', 'conv_in_kernel', 'resnet_time_scale_shift', 'upcast_attention', 'class_embed_type', 'mid_block_type', 'dual_cross_attention', 'projection_class_embeddings_input_dim', 'num_class_embeds', 'class_embeddings_concat', 'time_cond_proj_dim', 'only_cross_attention'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('vs/workbench/api/node/extensionHostProcess')}\n",
      "  warn(msg)\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('//matplotlib_inline.backend_inline'), PosixPath('module')}\n",
      "  warn(msg)\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:136: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/tmp/torchelastic_l_vkyxu6/none_99edfheh/attempt_0/0/error.json')}\n",
      "  warn(msg)\n",
      "CUDA_SETUP: WARNING! libcudart.so not found in any environmental path. Searching /usr/local/cuda/lib64...\n",
      "CUDA SETUP: CUDA runtime path found: /usr/local/cuda/lib64/libcudart.so\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 7.5\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /home/shane/projects/.venv/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117.so...\n",
      "Using /home/shane/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/shane/.cache/torch_extensions/py310_cu117/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module cpu_adam...\n",
      "Time to load cpu_adam op: 2.193203926086426 seconds\n",
      "Adam Optimizer #0 is created with AVX2 arithmetic capability.\n",
      "Config: alpha=0.000005, betas=(0.900000, 0.999000), weight_decay=0.010000, adam_w=1\n",
      "[2023-04-01 12:58:49,533] [INFO] [logging.py:93:log_dist] [Rank -1] DeepSpeed info: version=0.8.3, git-hash=unknown, git-branch=unknown\n",
      "04/01/2023 12:58:56 - INFO - torch.distributed.distributed_c10d - Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "04/01/2023 12:58:56 - INFO - torch.distributed.distributed_c10d - Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 1 nodes.\n",
      "[2023-04-01 12:58:56,277] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Flops Profiler Enabled: False\n",
      "[2023-04-01 12:58:56,278] [INFO] [logging.py:93:log_dist] [Rank 0] Removing param_group that has no 'params' in the client Optimizer\n",
      "[2023-04-01 12:58:56,278] [INFO] [logging.py:93:log_dist] [Rank 0] Using client Optimizer as basic optimizer\n",
      "[2023-04-01 12:58:56,325] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Basic Optimizer = DeepSpeedCPUAdam\n",
      "[2023-04-01 12:58:56,325] [INFO] [utils.py:55:is_zero_supported_optimizer] Checking ZeRO support for optimizer=DeepSpeedCPUAdam type=<class 'deepspeed.ops.adam.cpu_adam.DeepSpeedCPUAdam'>\n",
      "[2023-04-01 12:58:56,325] [INFO] [logging.py:93:log_dist] [Rank 0] Creating torch.float16 ZeRO stage 2 optimizer\n",
      "[2023-04-01 12:58:56,325] [INFO] [stage_1_and_2.py:144:__init__] Reduce bucket size 500,000,000\n",
      "[2023-04-01 12:58:56,325] [INFO] [stage_1_and_2.py:145:__init__] Allgather bucket size 500,000,000\n",
      "[2023-04-01 12:58:56,325] [INFO] [stage_1_and_2.py:146:__init__] CPU Offload: True\n",
      "[2023-04-01 12:58:56,325] [INFO] [stage_1_and_2.py:147:__init__] Round robin gradient partitioning: False\n",
      "Using /home/shane/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/shane/.cache/torch_extensions/py310_cu117/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "ninja: no work to do.\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.05232858657836914 seconds\n",
      "Rank: 0 partition count [1] and sizes[(859520964, False)] \n",
      "[2023-04-01 12:58:58,313] [INFO] [utils.py:829:see_memory_usage] Before initializing optimizer states\n",
      "[2023-04-01 12:58:58,313] [INFO] [utils.py:830:see_memory_usage] MA 1.66 GB         Max_MA 1.66 GB         CA 1.66 GB         Max_CA 2 GB \n",
      "[2023-04-01 12:58:58,313] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 12.15 GB, percent = 38.8%\n",
      "[2023-04-01 12:59:01,959] [INFO] [utils.py:829:see_memory_usage] After initializing optimizer states\n",
      "[2023-04-01 12:59:01,961] [INFO] [utils.py:830:see_memory_usage] MA 1.66 GB         Max_MA 1.66 GB         CA 1.66 GB         Max_CA 2 GB \n",
      "[2023-04-01 12:59:01,961] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 22.51 GB, percent = 71.9%\n",
      "[2023-04-01 12:59:01,961] [INFO] [stage_1_and_2.py:520:__init__] optimizer state initialized\n",
      "[2023-04-01 12:59:02,016] [INFO] [utils.py:829:see_memory_usage] After initializing ZeRO optimizer\n",
      "[2023-04-01 12:59:02,017] [INFO] [utils.py:830:see_memory_usage] MA 1.66 GB         Max_MA 1.66 GB         CA 1.66 GB         Max_CA 2 GB \n",
      "[2023-04-01 12:59:02,017] [INFO] [utils.py:838:see_memory_usage] CPU Virtual Memory:  used = 22.51 GB, percent = 71.9%\n",
      "[2023-04-01 12:59:02,037] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed Final Optimizer = DeepSpeedCPUAdam\n",
      "[2023-04-01 12:59:02,037] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed using client LR scheduler\n",
      "[2023-04-01 12:59:02,037] [INFO] [logging.py:93:log_dist] [Rank 0] DeepSpeed LR Scheduler = None\n",
      "[2023-04-01 12:59:02,037] [INFO] [logging.py:93:log_dist] [Rank 0] step=0, skipped=0, lr=[5e-06], mom=[(0.9, 0.999)]\n",
      "[2023-04-01 12:59:02,038] [INFO] [config.py:1018:print] DeepSpeedEngine configuration:\n",
      "[2023-04-01 12:59:02,038] [INFO] [config.py:1022:print]   activation_checkpointing_config  {\n",
      "    \"partition_activations\": false, \n",
      "    \"contiguous_memory_optimization\": false, \n",
      "    \"cpu_checkpointing\": false, \n",
      "    \"number_checkpoints\": null, \n",
      "    \"synchronize_checkpoint_boundary\": false, \n",
      "    \"profile\": false\n",
      "}\n",
      "[2023-04-01 12:59:02,038] [INFO] [config.py:1022:print]   aio_config ................... {'block_size': 1048576, 'queue_depth': 8, 'thread_count': 1, 'single_submit': False, 'overlap_events': True}\n",
      "[2023-04-01 12:59:02,038] [INFO] [config.py:1022:print]   amp_enabled .................. False\n",
      "[2023-04-01 12:59:02,038] [INFO] [config.py:1022:print]   amp_params ................... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   autotuning_config ............ {\n",
      "    \"enabled\": false, \n",
      "    \"start_step\": null, \n",
      "    \"end_step\": null, \n",
      "    \"metric_path\": null, \n",
      "    \"arg_mappings\": null, \n",
      "    \"metric\": \"throughput\", \n",
      "    \"model_info\": null, \n",
      "    \"results_dir\": \"autotuning_results\", \n",
      "    \"exps_dir\": \"autotuning_exps\", \n",
      "    \"overwrite\": true, \n",
      "    \"fast\": true, \n",
      "    \"start_profile_step\": 3, \n",
      "    \"end_profile_step\": 5, \n",
      "    \"tuner_type\": \"gridsearch\", \n",
      "    \"tuner_early_stopping\": 5, \n",
      "    \"tuner_num_trials\": 50, \n",
      "    \"model_info_path\": null, \n",
      "    \"mp_size\": 1, \n",
      "    \"max_train_batch_size\": null, \n",
      "    \"min_train_batch_size\": 1, \n",
      "    \"max_train_micro_batch_size_per_gpu\": 1.024000e+03, \n",
      "    \"min_train_micro_batch_size_per_gpu\": 1, \n",
      "    \"num_tuning_micro_batch_sizes\": 3\n",
      "}\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   bfloat16_enabled ............. False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   checkpoint_parallel_write_pipeline  False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   checkpoint_tag_validation_enabled  True\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   checkpoint_tag_validation_fail  False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   comms_config ................. <deepspeed.comm.config.DeepSpeedCommsConfig object at 0x7f57c7d55840>\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   communication_data_type ...... None\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   compression_config ........... {'weight_quantization': {'shared_parameters': {'enabled': False, 'quantizer_kernel': False, 'schedule_offset': 0, 'quantize_groups': 1, 'quantize_verbose': False, 'quantization_type': 'symmetric', 'quantize_weight_in_forward': False, 'rounding': 'nearest', 'fp16_mixed_quantize': False, 'quantize_change_ratio': 0.001}, 'different_groups': {}}, 'activation_quantization': {'shared_parameters': {'enabled': False, 'quantization_type': 'symmetric', 'range_calibration': 'dynamic', 'schedule_offset': 1000}, 'different_groups': {}}, 'sparse_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'row_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'head_pruning': {'shared_parameters': {'enabled': False, 'method': 'topk', 'schedule_offset': 1000}, 'different_groups': {}}, 'channel_pruning': {'shared_parameters': {'enabled': False, 'method': 'l1', 'schedule_offset': 1000}, 'different_groups': {}}, 'layer_reduction': {'enabled': False}}\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   curriculum_enabled_legacy .... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   curriculum_params_legacy ..... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   data_efficiency_config ....... {'enabled': False, 'seed': 1234, 'data_sampling': {'enabled': False, 'num_epochs': 1000, 'num_workers': 0, 'curriculum_learning': {'enabled': False}}, 'data_routing': {'enabled': False, 'random_ltd': {'enabled': False, 'layer_token_lr_schedule': {'enabled': False}}}}\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   data_efficiency_enabled ...... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   dataloader_drop_last ......... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   disable_allgather ............ False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   dump_state ................... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   dynamic_loss_scale_args ...... None\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_enabled ........... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_gas_boundary_resolution  1\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_layer_name ........ bert.encoder.layer\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_layer_num ......... 0\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_max_iter .......... 100\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_stability ......... 1e-06\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_tol ............... 0.01\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   eigenvalue_verbose ........... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   elasticity_enabled ........... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   flops_profiler_config ........ {\n",
      "    \"enabled\": false, \n",
      "    \"profile_step\": 1, \n",
      "    \"module_depth\": -1, \n",
      "    \"top_modules\": 1, \n",
      "    \"detailed\": true, \n",
      "    \"output_file\": null\n",
      "}\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   fp16_auto_cast ............... True\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   fp16_enabled ................. True\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   fp16_master_weights_and_gradients  False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   global_rank .................. 0\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   grad_accum_dtype ............. None\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   gradient_accumulation_steps .. 1\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   gradient_clipping ............ 0.0\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   gradient_predivide_factor .... 1.0\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   initial_dynamic_scale ........ 65536\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   load_universal_checkpoint .... False\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   loss_scale ................... 0\n",
      "[2023-04-01 12:59:02,039] [INFO] [config.py:1022:print]   memory_breakdown ............. False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   monitor_config ............... tensorboard=TensorBoardConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') wandb=WandbConfig(enabled=False, group=None, team=None, project='deepspeed') csv_monitor=CSVConfig(enabled=False, output_path='', job_name='DeepSpeedJobName') enabled=False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   nebula_config ................ {\n",
      "    \"enabled\": false, \n",
      "    \"persistent_storage_path\": null, \n",
      "    \"persistent_time_interval\": 100, \n",
      "    \"num_of_version_in_retention\": 2, \n",
      "    \"enable_nebula_load\": true, \n",
      "    \"load_path\": null\n",
      "}\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   optimizer_legacy_fusion ...... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   optimizer_name ............... None\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   optimizer_params ............. None\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   pipeline ..................... {'stages': 'auto', 'partition': 'best', 'seed_layers': False, 'activation_checkpoint_interval': 0}\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   pld_enabled .................. False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   pld_params ................... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   prescale_gradients ........... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   scheduler_name ............... None\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   scheduler_params ............. None\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   sparse_attention ............. None\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   sparse_gradients_enabled ..... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   steps_per_print .............. inf\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   train_batch_size ............. 1\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   train_micro_batch_size_per_gpu  1\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   use_node_local_storage ....... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   wall_clock_breakdown ......... False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   world_size ................... 1\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   zero_allow_untested_optimizer  True\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   zero_config .................. stage=2 contiguous_gradients=True reduce_scatter=True reduce_bucket_size=500,000,000 allgather_partitions=True allgather_bucket_size=500,000,000 overlap_comm=False load_from_fp32_weights=True elastic_checkpoint=False offload_param=DeepSpeedZeroOffloadParamConfig(device='cpu', nvme_path=None, buffer_count=5, buffer_size=100,000,000, max_in_cpu=1,000,000,000, pin_memory=False) offload_optimizer=DeepSpeedZeroOffloadOptimizerConfig(device='cpu', nvme_path=None, buffer_count=4, pin_memory=False, pipeline=False, pipeline_read=False, pipeline_write=False, fast_init=False) sub_group_size=1,000,000,000 cpu_offload_param=None cpu_offload_use_pin_memory=None cpu_offload=None prefetch_bucket_size=50,000,000 param_persistence_threshold=100,000 model_persistence_threshold=sys.maxsize max_live_parameters=1,000,000,000 max_reuse_distance=1,000,000,000 gather_16bit_weights_on_model_save=False stage3_gather_fp16_weights_on_model_save=False ignore_unused_parameters=True legacy_stage1=False round_robin_gradients=False\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   zero_enabled ................. True\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   zero_force_ds_cpu_optimizer .. True\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1022:print]   zero_optimization_stage ...... 2\n",
      "[2023-04-01 12:59:02,040] [INFO] [config.py:1007:print_user_config]   json = {\n",
      "    \"train_batch_size\": 1, \n",
      "    \"train_micro_batch_size_per_gpu\": 1, \n",
      "    \"gradient_accumulation_steps\": 1, \n",
      "    \"zero_optimization\": {\n",
      "        \"stage\": 2, \n",
      "        \"offload_optimizer\": {\n",
      "            \"device\": \"cpu\"\n",
      "        }, \n",
      "        \"offload_param\": {\n",
      "            \"device\": \"cpu\"\n",
      "        }, \n",
      "        \"stage3_gather_16bit_weights_on_model_save\": false\n",
      "    }, \n",
      "    \"steps_per_print\": inf, \n",
      "    \"fp16\": {\n",
      "        \"enabled\": true, \n",
      "        \"auto_cast\": true\n",
      "    }, \n",
      "    \"bf16\": {\n",
      "        \"enabled\": false\n",
      "    }, \n",
      "    \"zero_allow_untested_optimizer\": true\n",
      "}\n",
      "Using /home/shane/.cache/torch_extensions/py310_cu117 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "Time to load utils op: 0.0009288787841796875 seconds\n",
      "04/01/2023 12:59:02 - INFO - __main__ - ***** Running training *****\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Num examples = 200\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Num batches each epoch = 200\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Num Epochs = 4\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Instantaneous batch size per device = 1\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "04/01/2023 12:59:02 - INFO - __main__ -   Total optimization steps = 800\n",
      "Steps:   0%|                                            | 0/800 [00:00<?, ?it/s]/home/shane/projects/.venv/lib/python3.10/site-packages/xformers/ops/fmha/flash.py:338: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  and inp.query.storage().data_ptr() == inp.key.storage().data_ptr()\n",
      "[2023-04-01 12:59:05,442] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4294967296, reducing to 2147483648\n",
      "Steps:   0%|              | 1/800 [00:02<34:49,  2.61s/it, loss=0.0168, lr=5e-6][2023-04-01 12:59:06,351] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2147483648, reducing to 1073741824\n",
      "Steps:   0%|              | 2/800 [00:03<21:26,  1.61s/it, loss=0.0483, lr=5e-6][2023-04-01 12:59:07,256] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 1073741824, reducing to 536870912\n",
      "Steps:   0%|               | 3/800 [00:04<17:07,  1.29s/it, loss=0.137, lr=5e-6][2023-04-01 12:59:08,158] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 536870912, reducing to 268435456\n",
      "Steps:   0%|               | 4/800 [00:05<15:04,  1.14s/it, loss=0.037, lr=5e-6][2023-04-01 12:59:09,026] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 268435456, reducing to 134217728\n",
      "Steps:   1%|              | 5/800 [00:06<13:46,  1.04s/it, loss=0.0855, lr=5e-6][2023-04-01 12:59:09,927] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 134217728, reducing to 67108864\n",
      "Steps:   1%|               | 6/800 [00:07<13:07,  1.01it/s, loss=0.207, lr=5e-6][2023-04-01 12:59:10,832] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 67108864, reducing to 33554432\n",
      "Steps:   1%|              | 7/800 [00:08<12:44,  1.04it/s, loss=0.0314, lr=5e-6][2023-04-01 12:59:11,730] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 33554432, reducing to 16777216\n",
      "Steps:   1%|▏              | 8/800 [00:08<12:26,  1.06it/s, loss=0.114, lr=5e-6][2023-04-01 12:59:12,601] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 16777216, reducing to 8388608\n",
      "Steps:   1%|▏           | 10/800 [00:12<18:07,  1.38s/it, loss=0.00631, lr=5e-6][2023-04-01 12:59:15,910] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 8388608, reducing to 4194304\n",
      "Steps:   2%|▏            | 12/800 [00:15<20:34,  1.57s/it, loss=0.0915, lr=5e-6][2023-04-01 12:59:19,148] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 4194304, reducing to 2097152\n",
      "Steps:   3%|▍             | 26/800 [00:46<30:01,  2.33s/it, loss=0.264, lr=5e-6][2023-04-01 12:59:50,339] [INFO] [loss_scaler.py:173:update_scale] [deepspeed] OVERFLOW! Rank 0 Skipping step. Attempted loss scale: 2097152, reducing to 1048576\n",
      "Steps:  62%|████████▏    | 500/800 [19:21<11:48,  2.36s/it, loss=0.273, lr=5e-6]04/01/2023 13:18:23 - INFO - accelerate.accelerator - Saving current state to ./content/stable_diffusion_weights/sks/checkpoint-500\n",
      "04/01/2023 13:18:23 - INFO - accelerate.accelerator - Saving DeepSpeed Model and Optimizer\n",
      "[2023-04-01 13:18:23,981] [INFO] [logging.py:93:log_dist] [Rank 0] [Torch] Checkpoint pytorch_model is about to be saved!\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1802: UserWarning: Positional args are being deprecated, use kwargs instead. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "[2023-04-01 13:18:23,990] [INFO] [logging.py:93:log_dist] [Rank 0] Saving model checkpoint: ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt\n",
      "[2023-04-01 13:18:23,990] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saving ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt...\n",
      "[2023-04-01 13:18:26,236] [INFO] [torch_checkpoint_engine.py:19:save] [Torch] Saved ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/mp_rank_00_model_states.pt.\n",
      "[2023-04-01 13:18:26,237] [INFO] [torch_checkpoint_engine.py:17:save] [Torch] Saving ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt...\n",
      "[2023-04-01 13:18:46,370] [INFO] [torch_checkpoint_engine.py:19:save] [Torch] Saved ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt.\n",
      "[2023-04-01 13:18:46,372] [INFO] [engine.py:3430:_save_zero_checkpoint] zero checkpoint saved ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/zero_pp_rank_0_mp_rank_00_optim_states.pt\n",
      "[2023-04-01 13:18:46,372] [INFO] [torch_checkpoint_engine.py:29:commit] [Torch] Checkpoint pytorch_model is ready now!\n",
      "04/01/2023 13:18:46 - INFO - accelerate.accelerator - DeepSpeed Model and Optimizer saved to output dir ./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model\n",
      "Configuration saved in ./content/stable_diffusion_weights/sks/checkpoint-500/unet/config.json\n",
      "Model weights saved in ./content/stable_diffusion_weights/sks/checkpoint-500/unet/diffusion_pytorch_model.bin\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/ai_learning/\u001b[0m\u001b[1;33mtrain_dreambooth.py\u001b[0m:\u001b[94m1053\u001b[0m in \u001b[92m<module>\u001b[0m        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1050 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1051 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1052 \u001b[0m\u001b[2m│   \u001b[0margs = parse_args()                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1053 \u001b[2m│   \u001b[0mmain(args)                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1054 \u001b[0m                                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/ai_learning/\u001b[0m\u001b[1;33mtrain_dreambooth.py\u001b[0m:\u001b[94m1021\u001b[0m in \u001b[92mmain\u001b[0m            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1018 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m accelerator.is_main_process:                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1019 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m global_step % args.checkpointing_steps == \u001b[94m0\u001b[0m:   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1020 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0msave_path = os.path.join(args.output_dir, \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mc\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1021 \u001b[2m│   │   │   │   │   │   \u001b[0maccelerator.save_state(save_path)             \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1022 \u001b[0m\u001b[2m│   │   │   │   │   │   \u001b[0mlogger.info(\u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33mSaved state to \u001b[0m\u001b[33m{\u001b[0msave_path\u001b[33m}\u001b[0m\u001b[33m\"\u001b[0m)    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1023 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m                                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m1024 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0m\u001b[94mif\u001b[0m args.validation_prompt \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m global_ \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerat\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mor.py\u001b[0m:\u001b[94m2277\u001b[0m in \u001b[92msave_state\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2274 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Call model loading hooks that might have been registered wi\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2275 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# accelerator.register_model_state_hook\u001b[0m                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2276 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m hook \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._save_model_state_pre_hook.values():         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2277 \u001b[2m│   │   │   \u001b[0mhook(\u001b[96mself\u001b[0m._models, weights, output_dir)                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2278 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2279 \u001b[0m\u001b[2m│   │   \u001b[0msave_location = save_accelerator_state(                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m2280 \u001b[0m\u001b[2m│   │   │   \u001b[0moutput_dir, weights, optimizers, schedulers, \u001b[96mself\u001b[0m.state.p \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/ai_learning/\u001b[0m\u001b[1;33mtrain_dreambooth.py\u001b[0m:\u001b[94m729\u001b[0m in \u001b[92msave_model_hook\u001b[0m  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 726 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mmodel.save_pretrained(os.path.join(output_dir, sub_di \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 727 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m                                                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 728 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[2m# make sure to pop weight so that corresponding model\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 729 \u001b[2m│   │   │   │   \u001b[0mweights.pop()                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 730 \u001b[0m\u001b[2m│   │   \u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 731 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mload_model_hook\u001b[0m(models, input_dir):                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m 732 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwhile\u001b[0m \u001b[96mlen\u001b[0m(models) > \u001b[94m0\u001b[0m:                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mIndexError: \u001b[0mpop from empty list\n",
      "Steps:  62%|████████▏    | 500/800 [19:47<11:52,  2.38s/it, loss=0.273, lr=5e-6]\n",
      "\u001b[2;36m[13:18:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m failed \u001b[1m(\u001b[0mexitcode: \u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m local_rank: \u001b[1;36m0\u001b[0m \u001b[1m(\u001b[0mpid: \u001b[1;36m6809\u001b[0m\u001b[1m)\u001b[0m of \u001b]8;id=6584;file:///home/shane/projects/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py\u001b\\\u001b[2mapi.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=779121;file:///home/shane/projects/.venv/lib/python3.10/site-packages/torch/distributed/elastic/multiprocessing/api.py#672\u001b\\\u001b[2m672\u001b[0m\u001b]8;;\u001b\\\n",
      "\u001b[2;36m           \u001b[0m         binary: \u001b[35m/home/shane/projects/.venv/bin/\u001b[0m\u001b[95mpython\u001b[0m     \u001b[2m          \u001b[0m\n",
      "\u001b[31m╭─\u001b[0m\u001b[31m────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m─────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/bin/\u001b[0m\u001b[1;33maccelerate\u001b[0m:\u001b[94m8\u001b[0m in \u001b[92m<module>\u001b[0m                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m5 \u001b[0m\u001b[94mfrom\u001b[0m \u001b[4;96maccelerate\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96mcommands\u001b[0m\u001b[4;96m.\u001b[0m\u001b[4;96maccelerate_cli\u001b[0m \u001b[94mimport\u001b[0m main                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m6 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m'\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m'\u001b[0m:                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m7 \u001b[0m\u001b[2m│   \u001b[0msys.argv[\u001b[94m0\u001b[0m] = re.sub(\u001b[33mr\u001b[0m\u001b[33m'\u001b[0m\u001b[33m(-script\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.pyw|\u001b[0m\u001b[33m\\\u001b[0m\u001b[33m.exe)?$\u001b[0m\u001b[33m'\u001b[0m, \u001b[33m'\u001b[0m\u001b[33m'\u001b[0m, sys.argv[\u001b[94m0\u001b[0m])     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m8 \u001b[2m│   \u001b[0msys.exit(main())                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m9 \u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/commands/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33maccelerate_cli.py\u001b[0m:\u001b[94m45\u001b[0m in \u001b[92mmain\u001b[0m                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m42 \u001b[0m\u001b[2m│   │   \u001b[0mexit(\u001b[94m1\u001b[0m)                                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m43 \u001b[0m\u001b[2m│   \u001b[0m                                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m44 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Run\u001b[0m                                                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m45 \u001b[2m│   \u001b[0margs.func(args)                                                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m46 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m47 \u001b[0m                                                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m48 \u001b[0m\u001b[94mif\u001b[0m \u001b[91m__name__\u001b[0m == \u001b[33m\"\u001b[0m\u001b[33m__main__\u001b[0m\u001b[33m\"\u001b[0m:                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/commands/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mlaunch.py\u001b[0m:\u001b[94m908\u001b[0m in \u001b[92mlaunch_command\u001b[0m                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m905 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m mp_from_config_flag:                                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m906 \u001b[0m\u001b[2m│   │   │   \u001b[0margs.deepspeed_fields_from_accelerate_config.append(\u001b[33m\"\u001b[0m\u001b[33mmixed\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m907 \u001b[0m\u001b[2m│   │   \u001b[0margs.deepspeed_fields_from_accelerate_config = \u001b[33m\"\u001b[0m\u001b[33m,\u001b[0m\u001b[33m\"\u001b[0m.join(args.d \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m908 \u001b[2m│   │   \u001b[0mdeepspeed_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m909 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_fsdp \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m910 \u001b[0m\u001b[2m│   │   \u001b[0mmulti_gpu_launcher(args)                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m911 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melif\u001b[0m args.use_megatron_lm \u001b[95mand\u001b[0m \u001b[95mnot\u001b[0m args.cpu:                        \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/commands/\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mlaunch.py\u001b[0m:\u001b[94m647\u001b[0m in \u001b[92mdeepspeed_launcher\u001b[0m                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m644 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m645 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwith\u001b[0m patch_environment(**current_env):                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m646 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mtry\u001b[0m:                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m647 \u001b[2m│   │   │   │   \u001b[0mdistrib_run.run(args)                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m648 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mexcept\u001b[0m \u001b[96mException\u001b[0m:                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m649 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mif\u001b[0m is_rich_available() \u001b[95mand\u001b[0m debug:                      \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m650 \u001b[0m\u001b[2m│   │   │   │   │   \u001b[0mconsole = get_console()                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/distributed/\u001b[0m\u001b[1;33mru\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[1;33mn.py\u001b[0m:\u001b[94m785\u001b[0m in \u001b[92mrun\u001b[0m                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m782 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m783 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m784 \u001b[0m\u001b[2m│   \u001b[0mconfig, cmd, cmd_args = config_from_args(args)                     \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m785 \u001b[2m│   \u001b[0melastic_launch(                                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m786 \u001b[0m\u001b[2m│   │   \u001b[0mconfig=config,                                                 \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m787 \u001b[0m\u001b[2m│   │   \u001b[0mentrypoint=cmd,                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m788 \u001b[0m\u001b[2m│   \u001b[0m)(*cmd_args)                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/distributed/la\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33muncher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m134\u001b[0m in \u001b[92m__call__\u001b[0m                                                \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m131 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m._entrypoint = entrypoint                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m132 \u001b[0m\u001b[2m│   \u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m133 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__call__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m134 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m launch_agent(\u001b[96mself\u001b[0m._config, \u001b[96mself\u001b[0m._entrypoint, \u001b[96mlist\u001b[0m(args) \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m                                                                       \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_get_entrypoint_name\u001b[0m(                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/distributed/la\u001b[0m \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[2;33muncher/\u001b[0m\u001b[1;33mapi.py\u001b[0m:\u001b[94m250\u001b[0m in \u001b[92mlaunch_agent\u001b[0m                                            \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m                                                                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m247 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# if the error files for the failed children exist\u001b[0m         \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m248 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# @record will copy the first error (root cause)\u001b[0m           \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m249 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# to the error file of the launcher process.\u001b[0m               \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m250 \u001b[2m│   │   │   \u001b[0m\u001b[94mraise\u001b[0m ChildFailedError(                                    \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m251 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mname=entrypoint_name,                                  \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m252 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mfailures=result.failures,                              \u001b[31m│\u001b[0m\n",
      "\u001b[31m│\u001b[0m   \u001b[2m253 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                          \u001b[31m│\u001b[0m\n",
      "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
      "\u001b[1;91mChildFailedError: \u001b[0m\n",
      "============================================================\n",
      "train_dreambooth.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  \u001b[1m<\u001b[0m\u001b[1;95mNO_OTHER_FAILURES\u001b[0m\u001b[39m>\u001b[0m\n",
      "\u001b[39m------------------------------------------------------------\u001b[0m\n",
      "\u001b[39mRoot Cause \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mfirst observed failure\u001b[0m\u001b[1;39m)\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[1;39m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m]\u001b[0m\u001b[39m:\u001b[0m\n",
      "\u001b[39m  time      : \u001b[0m\u001b[1;36m2023\u001b[0m\u001b[39m-\u001b[0m\u001b[1;36m04\u001b[0m\u001b[39m-01_\u001b[0m\u001b[1;92m13:18:54\u001b[0m\n",
      "\u001b[39m  host      : shane-MS-7B17\u001b[0m\n",
      "\u001b[39m  rank      : \u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mlocal_rank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  exitcode  : \u001b[0m\u001b[1;36m1\u001b[0m\u001b[39m \u001b[0m\u001b[1;39m(\u001b[0m\u001b[39mpid: \u001b[0m\u001b[1;36m6809\u001b[0m\u001b[1;39m)\u001b[0m\n",
      "\u001b[39m  error_file: <N/A\u001b[0m\u001b[1m>\u001b[0m\n",
      "  traceback : To enable traceback see: \n",
      "\u001b[4;94mhttps://pytorch.org/docs/stable/elastic/errors.html\u001b[0m\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth.py {train_args}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shane/projects/.venv/lib/python3.10/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/safetensors/torch.py:99: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(filename, framework=\"pt\", device=device) as f:\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/torch/_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/torch/storage.py:899: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = cls(wrap_storage=untyped_storage)\n",
      "/home/shane/projects/.venv/lib/python3.10/site-packages/transformers/modeling_utils.py:402: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  with safe_open(checkpoint_file, framework=\"pt\") as f:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">12</span>                                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 9 │   </span>unet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">10 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">11 # Restore state from a checkpoint path. You have to use the absolute path here.</span>             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>12 accelerator.load_state(OUTPUT_DIR + <span style=\"color: #808000; text-decoration-color: #808000\">\"/checkpoint-500/pytorch_model\"</span>)                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">13 </span>                                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">14 # Rebuild the pipeline with the unwrapped models (assignment to .unet and .text_encoder </span>    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">15 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> low_mem:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">accelerator.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">2396</span> in        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_state</span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2393 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> hook <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._load_model_state_pre_hook.values():                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2394 │   │   │   </span>hook(models, input_dir)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2395 │   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2396 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>load_accelerator_state(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2397 │   │   │   </span>input_dir, models, optimizers, schedulers, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.state.process_index, <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.sc  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2398 │   │   </span>)                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2399 │   │   </span>custom_checkpoints = [f <span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> f <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> os.listdir(input_dir) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">\"custom_checkpoint\"</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">checkpointing.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">138</span> in       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load_accelerator_state</span>                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">135 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> i, model <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">enumerate</span>(models):                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">136 │   │   </span>weights_name = <span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>MODEL_NAME<span style=\"color: #808000; text-decoration-color: #808000\">}.bin\"</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> i == <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #808000; text-decoration-color: #808000\">f\"{</span>MODEL_NAME<span style=\"color: #808000; text-decoration-color: #808000\">}_{</span>i<span style=\"color: #808000; text-decoration-color: #808000\">}.bin\"</span>          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">137 │   │   </span>input_model_file = os.path.join(input_dir, weights_name)                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>138 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>models[i].load_state_dict(torch.load(input_model_file, map_location=<span style=\"color: #808000; text-decoration-color: #808000\">\"cpu\"</span>), **lo   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">139 │   </span>logger.info(<span style=\"color: #808000; text-decoration-color: #808000\">\"All model weights loaded successfully\"</span>)                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">140 │   </span>                                                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">141 │   # Optimizer states</span>                                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/shane/projects/.venv/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">791</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">load</span>       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 788 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'encoding'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> pickle_load_args.keys():                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 789 │   │   </span>pickle_load_args[<span style=\"color: #808000; text-decoration-color: #808000\">'encoding'</span>] = <span style=\"color: #808000; text-decoration-color: #808000\">'utf-8'</span>                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 790 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 791 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> _open_file_like(f, <span style=\"color: #808000; text-decoration-color: #808000\">'rb'</span>) <span style=\"color: #0000ff; text-decoration-color: #0000ff\">as</span> opened_file:                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 792 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_zipfile(opened_file):                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 793 │   │   │   # The zipfile reader is going to advance the current file position.</span>           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 794 │   │   │   # If we want to actually tail call to torch.jit.load, we need to</span>              <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/shane/projects/.venv/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">271</span> in            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open_file_like</span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 268 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 269 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_open_file_like</span>(name_or_buffer, mode):                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 270 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> _is_path(name_or_buffer):                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 271 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _open_file(name_or_buffer, mode)                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 272 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 273 │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> <span style=\"color: #808000; text-decoration-color: #808000\">'w'</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> mode:                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 274 │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> _open_buffer_writer(name_or_buffer)                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/shane/projects/.venv/lib/python3.10/site-packages/torch/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">serialization.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">252</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 249 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 250 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">class</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; text-decoration: underline\">_open_file</span>(_opener):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 251 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, name, mode):                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 252 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().<span style=\"color: #00ff00; text-decoration-color: #00ff00\">__init__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">open</span>(name, mode))                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 253 │   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 254 │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">__exit__</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 255 │   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.file_like.close()                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">FileNotFoundError: </span><span style=\"font-weight: bold\">[</span>Errno <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">]</span> No such file or directory: \n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">'./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/pytorch_model.bin'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m12\u001b[0m                                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 9 \u001b[0m\u001b[2m│   \u001b[0munet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m10 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m11 \u001b[0m\u001b[2m# Restore state from a checkpoint path. You have to use the absolute path here.\u001b[0m             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m12 accelerator.load_state(OUTPUT_DIR + \u001b[33m\"\u001b[0m\u001b[33m/checkpoint-500/pytorch_model\u001b[0m\u001b[33m\"\u001b[0m)                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m13 \u001b[0m                                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m14 \u001b[0m\u001b[2m# Rebuild the pipeline with the unwrapped models (assignment to .unet and .text_encoder \u001b[0m    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m15 \u001b[0m\u001b[94mif\u001b[0m low_mem:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33maccelerator.py\u001b[0m:\u001b[94m2396\u001b[0m in        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mload_state\u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2393 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m hook \u001b[95min\u001b[0m \u001b[96mself\u001b[0m._load_model_state_pre_hook.values():                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2394 \u001b[0m\u001b[2m│   │   │   \u001b[0mhook(models, input_dir)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2395 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2396 \u001b[2m│   │   \u001b[0mload_accelerator_state(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2397 \u001b[0m\u001b[2m│   │   │   \u001b[0minput_dir, models, optimizers, schedulers, \u001b[96mself\u001b[0m.state.process_index, \u001b[96mself\u001b[0m.sc  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2398 \u001b[0m\u001b[2m│   │   \u001b[0m)                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2399 \u001b[0m\u001b[2m│   │   \u001b[0mcustom_checkpoints = [f \u001b[94mfor\u001b[0m f \u001b[95min\u001b[0m os.listdir(input_dir) \u001b[94mif\u001b[0m \u001b[33m\"\u001b[0m\u001b[33mcustom_checkpoint\u001b[0m\u001b[33m\"\u001b[0m \u001b[95min\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/accelerate/\u001b[0m\u001b[1;33mcheckpointing.py\u001b[0m:\u001b[94m138\u001b[0m in       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mload_accelerator_state\u001b[0m                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m135 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mfor\u001b[0m i, model \u001b[95min\u001b[0m \u001b[96menumerate\u001b[0m(models):                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m136 \u001b[0m\u001b[2m│   │   \u001b[0mweights_name = \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mMODEL_NAME\u001b[33m}\u001b[0m\u001b[33m.bin\u001b[0m\u001b[33m\"\u001b[0m \u001b[94mif\u001b[0m i == \u001b[94m0\u001b[0m \u001b[94melse\u001b[0m \u001b[33mf\u001b[0m\u001b[33m\"\u001b[0m\u001b[33m{\u001b[0mMODEL_NAME\u001b[33m}\u001b[0m\u001b[33m_\u001b[0m\u001b[33m{\u001b[0mi\u001b[33m}\u001b[0m\u001b[33m.bin\u001b[0m\u001b[33m\"\u001b[0m          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m137 \u001b[0m\u001b[2m│   │   \u001b[0minput_model_file = os.path.join(input_dir, weights_name)                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m138 \u001b[2m│   │   \u001b[0mmodels[i].load_state_dict(torch.load(input_model_file, map_location=\u001b[33m\"\u001b[0m\u001b[33mcpu\u001b[0m\u001b[33m\"\u001b[0m), **lo   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m139 \u001b[0m\u001b[2m│   \u001b[0mlogger.info(\u001b[33m\"\u001b[0m\u001b[33mAll model weights loaded successfully\u001b[0m\u001b[33m\"\u001b[0m)                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m140 \u001b[0m\u001b[2m│   \u001b[0m                                                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m141 \u001b[0m\u001b[2m│   \u001b[0m\u001b[2m# Optimizer states\u001b[0m                                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m791\u001b[0m in \u001b[92mload\u001b[0m       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 788 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mencoding\u001b[0m\u001b[33m'\u001b[0m \u001b[95mnot\u001b[0m \u001b[95min\u001b[0m pickle_load_args.keys():                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 789 \u001b[0m\u001b[2m│   │   \u001b[0mpickle_load_args[\u001b[33m'\u001b[0m\u001b[33mencoding\u001b[0m\u001b[33m'\u001b[0m] = \u001b[33m'\u001b[0m\u001b[33mutf-8\u001b[0m\u001b[33m'\u001b[0m                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 790 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 791 \u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m _open_file_like(f, \u001b[33m'\u001b[0m\u001b[33mrb\u001b[0m\u001b[33m'\u001b[0m) \u001b[94mas\u001b[0m opened_file:                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 792 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m _is_zipfile(opened_file):                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 793 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# The zipfile reader is going to advance the current file position.\u001b[0m           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 794 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# If we want to actually tail call to torch.jit.load, we need to\u001b[0m              \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m271\u001b[0m in            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_open_file_like\u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 268 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 269 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_open_file_like\u001b[0m(name_or_buffer, mode):                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 270 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mif\u001b[0m _is_path(name_or_buffer):                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 271 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m _open_file(name_or_buffer, mode)                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 272 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94melse\u001b[0m:                                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 273 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mif\u001b[0m \u001b[33m'\u001b[0m\u001b[33mw\u001b[0m\u001b[33m'\u001b[0m \u001b[95min\u001b[0m mode:                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 274 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m _open_buffer_writer(name_or_buffer)                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/shane/projects/.venv/lib/python3.10/site-packages/torch/\u001b[0m\u001b[1;33mserialization.py\u001b[0m:\u001b[94m252\u001b[0m in \u001b[92m__init__\u001b[0m   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 249 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 250 \u001b[0m\u001b[94mclass\u001b[0m \u001b[4;92m_open_file\u001b[0m(_opener):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 251 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__init__\u001b[0m(\u001b[96mself\u001b[0m, name, mode):                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 252 \u001b[2m│   │   \u001b[0m\u001b[96msuper\u001b[0m().\u001b[92m__init__\u001b[0m(\u001b[96mopen\u001b[0m(name, mode))                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 253 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 254 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m__exit__\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 255 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m.file_like.close()                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mFileNotFoundError: \u001b[0m\u001b[1m[\u001b[0mErrno \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m No such file or directory: \n",
       "\u001b[32m'./content/stable_diffusion_weights/sks/checkpoint-500/pytorch_model/pytorch_model.bin'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the pipeline with the same arguments (model, revision) that were used for training\n",
    "pipeline = DiffusionPipeline.from_pretrained(MODEL_NAME)\n",
    "accelerator = Accelerator()\n",
    "\n",
    "# Use text_encoder if `--train_text_encoder` was used for the initial training\n",
    "if low_mem:\n",
    "    unet = accelerator.prepare(pipeline.unet)\n",
    "else: \n",
    "    unet, text_encoder = accelerator.prepare(pipeline.unet, pipeline.text_encoder)\n",
    "\n",
    "# Restore state from a checkpoint path. You have to use the absolute path here.\n",
    "accelerator.load_state(OUTPUT_DIR + \"/checkpoint-500/pytorch_model\")\n",
    "\n",
    "# Rebuild the pipeline with the unwrapped models (assignment to .unet and .text_encoder should work too)\n",
    "if low_mem:\n",
    "    pipeline = DiffusionPipeline.from_pretrained(MODEL_NAME, unet=accelerator.unwrap_model(unet))\n",
    "else: \n",
    "    pipeline = DiffusionPipeline.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        unet=accelerator.unwrap_model(unet),\n",
    "        text_encoder=accelerator.unwrap_model(text_encoder),\n",
    "    )\n",
    "\n",
    "# Perform inference, or save, or push to the hub\n",
    "pipeline.save_pretrained(\"dreambooth-pipeline\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
